{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Newsgroup 토픽 모델링\n",
    "\n",
    "**20개 중 8개의 주제 데이터 로드 및 Count기반 피처 벡터화. LDA는 Count기반 Vectorizer만 적용합니다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer Shape: (7862, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. \n",
    "cats = ['rec.motorcycles', 'rec.sport.baseball', 'comp.graphics', 'comp.windows.x',\n",
    "        'talk.politics.mideast', 'soc.religion.christian', 'sci.electronics', 'sci.med'  ]\n",
    "\n",
    "# 위에서 cats 변수로 기재된 category만 추출. featch_20newsgroups( )의 categories에 cats 입력\n",
    "news_df= fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'), \n",
    "                            categories=cats, random_state=0)\n",
    "\n",
    "#LDA 는 Count기반의 Vectorizer만 적용합니다.  \n",
    "count_vect = CountVectorizer(max_df=0.95, max_features=1000, min_df=2, stop_words='english', ngram_range=(1,2))\n",
    "feat_vect = count_vect.fit_transform(news_df.data)\n",
    "print('CountVectorizer Shape:', feat_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#참고\n",
    "news_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA 객체 생성 후 Count 피처 벡터화 객체로 LDA수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=8, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=8, random_state=0)\n",
    "lda.fit(feat_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-LDA 하이퍼파라미터 관련 질문) LDA가 동작하는 과정 중에서 모든 단어들이 토픽 할당 분포가 변경되지 않을 때까지 반복적인 수행을 거치기 때문에 이에 관련된 파라미터로 max_iter가 있다고 하셨습니다. 그렇다면 혹시 max_iter를 예를들어 300으로 설정했는데 알고리즘이 동작하다가 200번째에 모든 단어들의 토픽 할당이 수렴이 된다면 그 때 바로 그냥 멈추고 결과를 출력하나요? (마치 XGBoost나 뉴럴네트워크 처럼 early_stopping 기능처럼요)  \n",
    "\n",
    "-답변) 네 맞습니다. LDA 내부 알고리즘이 EM(Expectation Maximization) step을 반복하는데 수렴이 될 경우 max_iter까지 반복하지 않고 종료됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**각 토픽 모델링 주제별 단어들의 연관도 확인**  \n",
    "lda객체의 components_ 속성은 주제별로 개별 단어들의 연관도 정규화 숫자가 들어있음\n",
    "\n",
    "shape는 주제 개수 X 피처 단어 개수  \n",
    "\n",
    "components_ 에 들어 있는 숫자값은 각 주제별로 단어가 나타난 횟수를 정규화 하여 나타냄.   \n",
    "\n",
    "숫자가 클 수록 토픽에서 단어가 차지하는 비중이 높음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.87175875e+02, 3.26401283e+02, 1.67643972e+02, ...,\n",
       "        7.19452113e+01, 1.25032429e-01, 1.25031801e-01],\n",
       "       [1.25100534e-01, 1.25200157e-01, 1.25116306e-01, ...,\n",
       "        5.23417043e+00, 1.25013172e-01, 1.25003054e-01],\n",
       "       [8.10165562e+01, 1.29756513e+01, 1.58877134e+01, ...,\n",
       "        2.02263029e+01, 1.25006040e-01, 1.25000074e-01],\n",
       "       ...,\n",
       "       [4.47519574e+01, 2.07610664e-01, 4.16627335e+00, ...,\n",
       "        6.91641165e+00, 1.25006504e-01, 1.25000079e-01],\n",
       "       [3.40790460e+01, 1.68526498e+01, 1.07933631e+01, ...,\n",
       "        6.35434267e+01, 1.25001835e-01, 1.25001866e-01],\n",
       "       [1.25080974e-01, 2.07187470e+02, 1.25006033e-01, ...,\n",
       "        6.49764265e+01, 2.62124935e+02, 2.49124958e+02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lda.components_.shape)\n",
    "lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**각 토픽별 중심 단어 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topic_words(model, feature_names, no_top_words):\n",
    "    for topic_index, topic in enumerate(model.components_): # 8개의 토픽이 순서대로 돌아감\n",
    "        print('\\nTopic #',topic_index)\n",
    "\n",
    "        # components_ array에서 가장 값이 큰 순으로 정렬했을 때, 그 값의 array index를 반환. \n",
    "        topic_word_indexes = topic.argsort()[::-1] #[::-1]은 argsort에서 내림차순의 의미\n",
    "        top_indexes=topic_word_indexes[:no_top_words]\n",
    "        \n",
    "        # top_indexes대상인 index별로 feature_names에 해당하는 word feature 추출 후 join으로 concat\n",
    "        feature_concat = ' + '.join([str(feature_names[i])+'*'+str(round(topic[i],1)) for i in top_indexes])                \n",
    "        print(feature_concat)\n",
    "\n",
    "# CountVectorizer객체내의 전체 word들의 명칭을 get_features_names( )를 통해 추출\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Topic별 가장 연관도가 높은 word를 15개만 추출(각 단어마다 정규화된 횟수도 같이 추출됨)\n",
    "display_topic_words(lda, feature_names, 15)\n",
    "\n",
    "# 모토사이클, 야구, 그래픽스, 윈도우즈, 중동, 기독교, 전자공학, 의학 등 8개 주제를 추출. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**개별 문서별 토픽 분포 확인**\n",
    "\n",
    "lda객체의 transform()을 수행하면 개별 문서별 토픽 분포를 반환함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7862, 8)\n",
      "[[0.01041839 0.55396999 0.01042574 0.38346606 0.01042319 0.01043351\n",
      "  0.01042806 0.01043505]\n",
      " [0.07922454 0.00186778 0.00186834 0.001869   0.00186785 0.79815854\n",
      "  0.00186917 0.11327478]\n",
      " [0.0036816  0.28344141 0.00368174 0.00368224 0.18191133 0.51623794\n",
      "  0.00368303 0.0036807 ]]\n"
     ]
    }
   ],
   "source": [
    "doc_topics = lda.transform(feat_vect)\n",
    "print(doc_topics.shape)\n",
    "print(doc_topics[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**개별 문서별 토픽 분포도를 출력**\n",
    "\n",
    "20newsgroup으로 만들어진 문서명을 출력.\n",
    "\n",
    "fetch_20newsgroups()으로 만들어진 데이터의 filename속성은 모든 문서의 문서명을 가지고 있음.\n",
    "\n",
    "filename속성은 절대 디렉토리를 가지는 문서명을 가지고 있으므로 '\\\\'로 분할하여 맨 마지막 두번째 부터 파일명으로 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename 개수: 7862 filename list 10개만: ['soc.religion.christian.20630', 'sci.med.59422', 'comp.graphics.38765', 'comp.graphics.38810', 'sci.med.59449', 'comp.graphics.38461', 'comp.windows.x.66959', 'rec.motorcycles.104487', 'sci.electronics.53875', 'sci.electronics.53617']\n"
     ]
    }
   ],
   "source": [
    "def get_filename_list(newsdata):\n",
    "    filename_list=[]\n",
    "\n",
    "    for file in newsdata.filenames:\n",
    "            #print(file) #(file 보면 C:\\~~~~\\~~\\~~ 이런식으로 되어 있음)\n",
    "            filename_temp = file.split('\\\\')[-2:] #'(\\'는 윈도우에서 '\\\\' 두개로 써야 함) \n",
    "            filename = '.'.join(filename_temp)\n",
    "            filename_list.append(filename)\n",
    "    \n",
    "    return filename_list\n",
    "\n",
    "filename_list = get_filename_list(news_df)\n",
    "print(\"filename 개수:\",len(filename_list), \"filename list 10개만:\",filename_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame으로 생성하여 문서별 토픽 분포도 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic #0</th>\n",
       "      <th>Topic #1</th>\n",
       "      <th>Topic #2</th>\n",
       "      <th>Topic #3</th>\n",
       "      <th>Topic #4</th>\n",
       "      <th>Topic #5</th>\n",
       "      <th>Topic #6</th>\n",
       "      <th>Topic #7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian.20630</th>\n",
       "      <td>0.010418</td>\n",
       "      <td>0.553970</td>\n",
       "      <td>0.010426</td>\n",
       "      <td>0.383466</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.010434</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.010435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59422</th>\n",
       "      <td>0.079225</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.798159</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.113275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38765</th>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.181911</td>\n",
       "      <td>0.516238</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38810</th>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.182998</td>\n",
       "      <td>0.381892</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.098440</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>0.003690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59449</th>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.536006</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.431327</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38461</th>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.622716</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.208271</td>\n",
       "      <td>0.147426</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.004315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x.66959</th>\n",
       "      <td>0.228170</td>\n",
       "      <td>0.574088</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.119577</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.015633</td>\n",
       "      <td>0.015633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.motorcycles.104487</th>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.893168</td>\n",
       "      <td>0.003055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics.53875</th>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.388058</td>\n",
       "      <td>0.005446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics.53617</th>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.926968</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.010421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics.54089</th>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.058054</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.731289</td>\n",
       "      <td>0.131841</td>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.baseball.102713</th>\n",
       "      <td>0.252383</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.029335</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.715184</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec.sport.baseball.104711</th>\n",
       "      <td>0.096592</td>\n",
       "      <td>0.398777</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.319705</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.164057</td>\n",
       "      <td>0.005219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.graphics.38232</th>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.490766</td>\n",
       "      <td>0.453903</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.003293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.electronics.52732</th>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.006259</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.784952</td>\n",
       "      <td>0.177490</td>\n",
       "      <td>0.006262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.mideast.76440</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.350379</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.634889</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sci.med.59243</th>\n",
       "      <td>0.296417</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.466075</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.222251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk.politics.mideast.75888</th>\n",
       "      <td>0.004820</td>\n",
       "      <td>0.842880</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.128241</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.004810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soc.religion.christian.21526</th>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.002317</td>\n",
       "      <td>0.751388</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.111426</td>\n",
       "      <td>0.125594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comp.windows.x.66408</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Topic #0  Topic #1  Topic #2  Topic #3  \\\n",
       "soc.religion.christian.20630  0.010418  0.553970  0.010426  0.383466   \n",
       "sci.med.59422                 0.079225  0.001868  0.001868  0.001869   \n",
       "comp.graphics.38765           0.003682  0.283441  0.003682  0.003682   \n",
       "comp.graphics.38810           0.003682  0.182998  0.381892  0.003684   \n",
       "sci.med.59449                 0.005443  0.005446  0.005441  0.536006   \n",
       "comp.graphics.38461           0.004316  0.622716  0.004317  0.208271   \n",
       "comp.windows.x.66959          0.228170  0.574088  0.015641  0.015627   \n",
       "rec.motorcycles.104487        0.042086  0.003057  0.049479  0.003051   \n",
       "sci.electronics.53875         0.005445  0.005439  0.005444  0.005439   \n",
       "sci.electronics.53617         0.010432  0.926968  0.010421  0.010435   \n",
       "sci.electronics.54089         0.001405  0.073190  0.001408  0.058054   \n",
       "rec.sport.baseball.102713     0.252383  0.000620  0.000619  0.000620   \n",
       "rec.sport.baseball.104711     0.096592  0.398777  0.005216  0.319705   \n",
       "comp.graphics.38232           0.038843  0.003306  0.003297  0.003296   \n",
       "sci.electronics.52732         0.006264  0.006262  0.006254  0.006259   \n",
       "talk.politics.mideast.76440   0.002457  0.350379  0.002455  0.634889   \n",
       "sci.med.59243                 0.296417  0.003051  0.003051  0.003052   \n",
       "talk.politics.mideast.75888   0.004820  0.842880  0.004812  0.004811   \n",
       "soc.religion.christian.21526  0.002319  0.002317  0.002317  0.751388   \n",
       "comp.windows.x.66408          0.000086  0.000086  0.000086  0.000086   \n",
       "\n",
       "                              Topic #4  Topic #5  Topic #6  Topic #7  \n",
       "soc.religion.christian.20630  0.010423  0.010434  0.010428  0.010435  \n",
       "sci.med.59422                 0.001868  0.798159  0.001869  0.113275  \n",
       "comp.graphics.38765           0.181911  0.516238  0.003683  0.003681  \n",
       "comp.graphics.38810           0.098440  0.003683  0.321931  0.003690  \n",
       "sci.med.59449                 0.005443  0.431327  0.005446  0.005448  \n",
       "comp.graphics.38461           0.147426  0.004320  0.004320  0.004315  \n",
       "comp.windows.x.66959          0.119577  0.015629  0.015633  0.015633  \n",
       "rec.motorcycles.104487        0.003051  0.003053  0.893168  0.003055  \n",
       "sci.electronics.53875         0.005438  0.579290  0.388058  0.005446  \n",
       "sci.electronics.53617         0.010439  0.010443  0.010441  0.010421  \n",
       "sci.electronics.54089         0.001407  0.731289  0.131841  0.001406  \n",
       "rec.sport.baseball.102713     0.029335  0.000620  0.715184  0.000619  \n",
       "rec.sport.baseball.104711     0.005217  0.005217  0.164057  0.005219  \n",
       "comp.graphics.38232           0.490766  0.453903  0.003296  0.003293  \n",
       "sci.electronics.52732         0.006256  0.784952  0.177490  0.006262  \n",
       "talk.politics.mideast.76440   0.002455  0.002456  0.002456  0.002453  \n",
       "sci.med.59243                 0.003051  0.466075  0.003053  0.222251  \n",
       "talk.politics.mideast.75888   0.004810  0.128241  0.004817  0.004810  \n",
       "soc.religion.christian.21526  0.002319  0.002320  0.111426  0.125594  \n",
       "comp.windows.x.66408          0.999395  0.000086  0.000086  0.000086  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "topic_names = ['Topic #'+ str(i) for i in range(0, 8)]\n",
    "doc_topic_df = pd.DataFrame(data=doc_topics, columns=topic_names, index=filename_list)\n",
    "doc_topic_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
